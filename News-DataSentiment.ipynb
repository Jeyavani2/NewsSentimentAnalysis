{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b69e4ff4-899f-40b3-ad5d-705a8a0b35bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: kaggle in c:\\users\\91904\\anaconda3\\lib\\site-packages (1.7.4.5)\n",
      "Requirement already satisfied: bleach in c:\\users\\91904\\anaconda3\\lib\\site-packages (from kaggle) (4.1.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in c:\\users\\91904\\anaconda3\\lib\\site-packages (from kaggle) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer in c:\\users\\91904\\anaconda3\\lib\\site-packages (from kaggle) (2.0.4)\n",
      "Requirement already satisfied: idna in c:\\users\\91904\\anaconda3\\lib\\site-packages (from kaggle) (3.4)\n",
      "Requirement already satisfied: protobuf in c:\\users\\91904\\anaconda3\\lib\\site-packages (from kaggle) (3.20.3)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\91904\\anaconda3\\lib\\site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\91904\\anaconda3\\lib\\site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: requests in c:\\users\\91904\\anaconda3\\lib\\site-packages (from kaggle) (2.32.3)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in c:\\users\\91904\\anaconda3\\lib\\site-packages (from kaggle) (68.2.2)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\91904\\anaconda3\\lib\\site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: text-unidecode in c:\\users\\91904\\anaconda3\\lib\\site-packages (from kaggle) (1.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\91904\\anaconda3\\lib\\site-packages (from kaggle) (4.65.0)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in c:\\users\\91904\\anaconda3\\lib\\site-packages (from kaggle) (1.26.20)\n",
      "Requirement already satisfied: webencodings in c:\\users\\91904\\anaconda3\\lib\\site-packages (from kaggle) (0.5.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\91904\\anaconda3\\lib\\site-packages (from bleach->kaggle) (23.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\91904\\anaconda3\\lib\\site-packages (from tqdm->kaggle) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    " pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75eeb564-fa6f-4463-adcd-38bcdb7c9c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/rmisra/news-category-dataset\n",
      "License(s): Attribution 4.0 International (CC BY 4.0)\n",
      "Downloading news-category-dataset.zip to C:\\Users\\91904\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/26.5M [00:00<?, ?B/s]\n",
      "100%|##########| 26.5M/26.5M [00:00<00:00, 331MB/s]\n"
     ]
    }
   ],
   "source": [
    " !kaggle datasets download -d rmisra/news-category-dataset --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2156f388-0a79-4c34-abb5-6c6a4b424fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "with ZipFile(r'C:\\Users\\91904\\news-category-dataset.zip','r')as zip_ref:\n",
    "    zip_ref.extractall()\n",
    "    zip_ref.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5102db3-7ad1-4d3f-b37d-ac0277ec4f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 209527 entries, 0 to 209526\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count   Dtype         \n",
      "---  ------             --------------   -----         \n",
      " 0   link               209527 non-null  object        \n",
      " 1   headline           209527 non-null  object        \n",
      " 2   category           209527 non-null  object        \n",
      " 3   short_description  209527 non-null  object        \n",
      " 4   authors            209527 non-null  object        \n",
      " 5   date               209527 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), object(5)\n",
      "memory usage: 9.6+ MB\n",
      "                                                link  \\\n",
      "0  https://www.huffpost.com/entry/covid-boosters-...   \n",
      "1  https://www.huffpost.com/entry/american-airlin...   \n",
      "2  https://www.huffpost.com/entry/funniest-tweets...   \n",
      "3  https://www.huffpost.com/entry/funniest-parent...   \n",
      "4  https://www.huffpost.com/entry/amy-cooper-lose...   \n",
      "\n",
      "                                            headline   category  \\\n",
      "0  Over 4 Million Americans Roll Up Sleeves For O...  U.S. NEWS   \n",
      "1  American Airlines Flyer Charged, Banned For Li...  U.S. NEWS   \n",
      "2  23 Of The Funniest Tweets About Cats And Dogs ...     COMEDY   \n",
      "3  The Funniest Tweets From Parents This Week (Se...  PARENTING   \n",
      "4  Woman Who Called Cops On Black Bird-Watcher Lo...  U.S. NEWS   \n",
      "\n",
      "                                   short_description               authors  \\\n",
      "0  Health experts said it is too early to predict...  Carla K. Johnson, AP   \n",
      "1  He was subdued by passengers and crew when he ...        Mary Papenfuss   \n",
      "2  \"Until you have a dog you don't understand wha...         Elyse Wanshel   \n",
      "3  \"Accidentally put grown-up toothpaste on my to...      Caroline Bologna   \n",
      "4  Amy Cooper accused investment firm Franklin Te...        Nina Golgowski   \n",
      "\n",
      "        date  \n",
      "0 2022-09-23  \n",
      "1 2022-09-23  \n",
      "2 2022-09-23  \n",
      "3 2022-09-23  \n",
      "4 2022-09-22  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_json(r'C:\\Users\\91904\\News_Category_Dataset_v3.json',lines=True)\n",
    "df.to_csv(r'C:\\Users\\91904\\news-category.csv',index=False)\n",
    "df.info()\n",
    "df.describe()\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fa33307-336e-4b9a-b5fd-29dade709f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>209527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2015-04-30 00:44:14.344308736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2012-01-28 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2013-08-10 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2015-03-16 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2016-11-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2022-09-23 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                date\n",
       "count                         209527\n",
       "mean   2015-04-30 00:44:14.344308736\n",
       "min              2012-01-28 00:00:00\n",
       "25%              2013-08-10 00:00:00\n",
       "50%              2015-03-16 00:00:00\n",
       "75%              2016-11-01 00:00:00\n",
       "max              2022-09-23 00:00:00"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "302863fb-f36e-47f2-bbc5-74ea32896513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: boto3 in c:\\users\\91904\\anaconda3\\lib\\site-packages (1.37.4)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.39.4-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: botocore in c:\\users\\91904\\anaconda3\\lib\\site-packages (1.37.4)\n",
      "Collecting botocore\n",
      "  Downloading botocore-1.39.4-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\91904\\anaconda3\\lib\\site-packages (1.26.20)\n",
      "Collecting urllib3\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\91904\\anaconda3\\lib\\site-packages (from boto3) (1.0.1)\n",
      "Collecting s3transfer<0.14.0,>=0.13.0 (from boto3)\n",
      "  Downloading s3transfer-0.13.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\91904\\anaconda3\\lib\\site-packages (from botocore) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\91904\\anaconda3\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore) (1.16.0)\n",
      "Downloading boto3-1.39.4-py3-none-any.whl (139 kB)\n",
      "   ---------------------------------------- 0.0/139.9 kB ? eta -:--:--\n",
      "   ----------------- --------------------- 61.4/139.9 kB 825.8 kB/s eta 0:00:01\n",
      "   ---------------------- ---------------- 81.9/139.9 kB 919.0 kB/s eta 0:00:01\n",
      "   ---------------------- ---------------- 81.9/139.9 kB 919.0 kB/s eta 0:00:01\n",
      "   -------------------------------------- 139.9/139.9 kB 831.2 kB/s eta 0:00:00\n",
      "Downloading botocore-1.39.4-py3-none-any.whl (13.8 MB)\n",
      "   ---------------------------------------- 0.0/13.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/13.8 MB 2.2 MB/s eta 0:00:07\n",
      "   ---------------------------------------- 0.1/13.8 MB 2.8 MB/s eta 0:00:05\n",
      "    --------------------------------------- 0.3/13.8 MB 2.3 MB/s eta 0:00:06\n",
      "    --------------------------------------- 0.3/13.8 MB 2.3 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.4/13.8 MB 1.4 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 0.4/13.8 MB 1.4 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 0.4/13.8 MB 1.4 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 0.7/13.8 MB 1.7 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 0.9/13.8 MB 1.8 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 1.1/13.8 MB 2.0 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 1.1/13.8 MB 2.0 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 1.1/13.8 MB 2.0 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 1.5/13.8 MB 2.0 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 1.7/13.8 MB 2.1 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 1.7/13.8 MB 2.0 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 1.7/13.8 MB 1.9 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 2.0/13.8 MB 2.1 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 2.1/13.8 MB 2.1 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 2.1/13.8 MB 2.0 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 2.3/13.8 MB 2.1 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 2.4/13.8 MB 2.1 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 2.6/13.8 MB 2.0 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 2.8/13.8 MB 2.1 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 3.0/13.8 MB 2.2 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 3.0/13.8 MB 2.2 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 3.2/13.8 MB 2.2 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 3.4/13.8 MB 2.2 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 3.5/13.8 MB 2.2 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 3.7/13.8 MB 2.3 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 3.8/13.8 MB 2.3 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 4.0/13.8 MB 2.3 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 4.1/13.8 MB 2.3 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 4.3/13.8 MB 2.4 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 4.3/13.8 MB 2.4 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 4.3/13.8 MB 2.3 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 4.7/13.8 MB 2.4 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 5.2/13.8 MB 2.5 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 5.4/13.8 MB 2.5 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 5.5/13.8 MB 2.5 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 5.5/13.8 MB 2.5 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 5.6/13.8 MB 2.5 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 5.7/13.8 MB 2.4 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 6.0/13.8 MB 2.5 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 6.1/13.8 MB 2.5 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 6.3/13.8 MB 2.6 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 6.5/13.8 MB 2.6 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 6.8/13.8 MB 2.6 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 7.0/13.8 MB 2.7 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 7.2/13.8 MB 2.7 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 7.3/13.8 MB 2.7 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 7.5/13.8 MB 2.7 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 7.7/13.8 MB 2.7 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 7.8/13.8 MB 2.8 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 7.9/13.8 MB 2.7 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 8.0/13.8 MB 2.8 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 8.0/13.8 MB 2.8 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 8.0/13.8 MB 2.8 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 8.7/13.8 MB 2.7 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 9.4/13.8 MB 2.9 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 9.4/13.8 MB 2.9 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 9.6/13.8 MB 2.8 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 10.1/13.8 MB 2.9 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 10.3/13.8 MB 3.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 10.3/13.8 MB 3.0 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 10.4/13.8 MB 3.0 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 10.8/13.8 MB 3.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 11.1/13.8 MB 3.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 11.3/13.8 MB 3.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 11.5/13.8 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 11.8/13.8 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 12.0/13.8 MB 3.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 12.3/13.8 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 12.5/13.8 MB 3.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 12.6/13.8 MB 3.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 12.9/13.8 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 12.9/13.8 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 12.9/13.8 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  13.5/13.8 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  13.6/13.8 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.8/13.8 MB 3.7 MB/s eta 0:00:00\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "   ---------------------------------------- 0.0/129.8 kB ? eta -:--:--\n",
      "   --------- ----------------------------- 30.7/129.8 kB 435.7 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 129.8/129.8 kB 1.3 MB/s eta 0:00:00\n",
      "Downloading s3transfer-0.13.0-py3-none-any.whl (85 kB)\n",
      "   ---------------------------------------- 0.0/85.2 kB ? eta -:--:--\n",
      "   -------------- ------------------------- 30.7/85.2 kB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 85.2/85.2 kB 1.6 MB/s eta 0:00:00\n",
      "Installing collected packages: urllib3, botocore, s3transfer, boto3\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.20\n",
      "    Uninstalling urllib3-1.26.20:\n",
      "      Successfully uninstalled urllib3-1.26.20\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.37.4\n",
      "    Uninstalling botocore-1.37.4:\n",
      "      Successfully uninstalled botocore-1.37.4\n",
      "  Attempting uninstall: s3transfer\n",
      "    Found existing installation: s3transfer 0.11.3\n",
      "    Uninstalling s3transfer-0.11.3:\n",
      "      Successfully uninstalled s3transfer-0.11.3\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.37.4\n",
      "    Uninstalling boto3-1.37.4:\n",
      "      Successfully uninstalled boto3-1.37.4\n",
      "Successfully installed boto3-1.39.4 botocore-1.39.4 s3transfer-0.13.0 urllib3-2.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "distributed 2025.2.0 requires cloudpickle>=3.0.0, but you have cloudpickle 2.2.1 which is incompatible.\n",
      "mlflow 2.8.0 requires pytz<2024, but you have pytz 2025.2 which is incompatible.\n",
      "selenium 4.2.0 requires urllib3[secure,socks]~=1.26, but you have urllib3 2.5.0 which is incompatible.\n",
      "tensorflow-intel 2.12.0rc0 requires numpy<1.24,>=1.22, but you have numpy 1.26.4 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade boto3 botocore urllib3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f75f2ff-4df9-42a6-8cd5-c6bd403a3f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from botocore.config import Config\n",
    "import boto3\n",
    "\n",
    "config = Config(\n",
    "    retries = {\n",
    "        'max_attempts': 10,\n",
    "        'mode': 'standard'\n",
    "    },\n",
    "    connect_timeout=30,\n",
    "    read_timeout=120\n",
    ")\n",
    "acc_key=\"AKIA2DK24S55T5V3RET7\"\n",
    "sec_key=\"Z9goqsPC1tTyhfo7It6+HXsnG6H//19h77LrLHQf\"\n",
    "s3 = boto3.client('s3', config=config,aws_access_key_id=acc_key,aws_secret_access_key=sec_key)\n",
    "\n",
    "file = r\"C:\\Users\\91904\\news-category.csv\"\n",
    "s3.upload_file(file, 'news-senticonomy-bucket', 'news-senti.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f2bd0d3-3234-42bc-ac2d-5f2bb05704a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 53751 entries, 13 to 209526\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   link               53751 non-null  object\n",
      " 1   headline           53749 non-null  object\n",
      " 2   category           53751 non-null  object\n",
      " 3   short_description  48550 non-null  object\n",
      " 4   authors            47071 non-null  object\n",
      " 5   date               53751 non-null  object\n",
      "dtypes: object(6)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(r\"C:\\Users\\91904\\news-category.csv\")\n",
    "df=df[df['category'].isin(['SPORTS','EDUCATION','BUSINESS','POLITICS','TECH','SCIENCE','MONEY'])]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f307a6e-edb1-4211-a31c-91b664a8d2e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "link                    0\n",
       "headline                2\n",
       "category                0\n",
       "short_description    5201\n",
       "authors              6680\n",
       "date                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "526639d8-59bc-405c-a5b7-f729aa76beb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna(how='any',subset=['headline','category','date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6505b7e-08a3-4bec-8a11-7631c2cb2cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     link  \\\n",
      "13      https://www.huffpost.com/entry/twitch-streamer...   \n",
      "17      https://www.huffpost.com/entry/dodgers-basebal...   \n",
      "21      https://www.huffpost.com/entry/biden-us-forces...   \n",
      "24      https://www.huffpost.com/entry/ukraine-festiva...   \n",
      "26      https://www.huffpost.com/entry/2022-wnba-final...   \n",
      "...                                                   ...   \n",
      "209522  https://www.huffingtonpost.com/entry/rim-ceo-t...   \n",
      "209523  https://www.huffingtonpost.com/entry/maria-sha...   \n",
      "209524  https://www.huffingtonpost.com/entry/super-bow...   \n",
      "209525  https://www.huffingtonpost.com/entry/aldon-smi...   \n",
      "209526  https://www.huffingtonpost.com/entry/dwight-ho...   \n",
      "\n",
      "                                                 headline  category  \\\n",
      "13      Twitch Bans Gambling Sites After Streamer Scam...      TECH   \n",
      "17      Maury Wills, Base-Stealing Shortstop For Dodge...    SPORTS   \n",
      "21      Biden Says U.S. Forces Would Defend Taiwan If ...  POLITICS   \n",
      "24      ‘Beautiful And Sad At The Same Time’: Ukrainia...  POLITICS   \n",
      "26      Las Vegas Aces Win First WNBA Title, Chelsea G...    SPORTS   \n",
      "...                                                   ...       ...   \n",
      "209522  RIM CEO Thorsten Heins' 'Significant' Plans Fo...      TECH   \n",
      "209523  Maria Sharapova Stunned By Victoria Azarenka I...    SPORTS   \n",
      "209524  Giants Over Patriots, Jets Over Colts Among  M...    SPORTS   \n",
      "209525  Aldon Smith Arrested: 49ers Linebacker Busted ...    SPORTS   \n",
      "209526  Dwight Howard Rips Teammates After Magic Loss ...    SPORTS   \n",
      "\n",
      "                                        short_description             authors  \\\n",
      "13      One man's claims that he scammed people on the...        Ben Blanchet   \n",
      "17      Maury Wills, who helped the Los Angeles Dodger...     Beth Harris, AP   \n",
      "21      President issues vow as tensions with China rise.                 NaN   \n",
      "24      An annual celebration took on a different feel...  Jonathan Nicholson   \n",
      "26      Las Vegas never had a professional sports cham...  Pat Eaton-Robb, AP   \n",
      "...                                                   ...                 ...   \n",
      "209522  Verizon Wireless and AT&T are already promotin...    Reuters, Reuters   \n",
      "209523  Afterward, Azarenka, more effusive with the pr...                 NaN   \n",
      "209524  Leading up to Super Bowl XLVI, the most talked...                 NaN   \n",
      "209525  CORRECTION: An earlier version of this story i...                 NaN   \n",
      "209526  The five-time all-star center tore into his te...                 NaN   \n",
      "\n",
      "              date  \n",
      "13      2022-09-21  \n",
      "17      2022-09-20  \n",
      "21      2022-09-19  \n",
      "24      2022-09-19  \n",
      "26      2022-09-19  \n",
      "...            ...  \n",
      "209522  2012-01-28  \n",
      "209523  2012-01-28  \n",
      "209524  2012-01-28  \n",
      "209525  2012-01-28  \n",
      "209526  2012-01-28  \n",
      "\n",
      "[53749 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10d052a1-87dc-4815-b79b-d4f7770fcd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date']=pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a0bf867-d446-4987-a572-a370e1a77e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'c:\\users\\91904\\after-news.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87765b91-5980-4f5d-91a5-2f72067ab9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 53749 entries, 13 to 209526\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   link               53749 non-null  object        \n",
      " 1   headline           53749 non-null  object        \n",
      " 2   category           53749 non-null  object        \n",
      " 3   short_description  48550 non-null  object        \n",
      " 4   authors            47069 non-null  object        \n",
      " 5   date               53749 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), object(5)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e6be5918-5e74-4eac-a02f-6d2c1923a1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "News data saved to news-category1.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from botocore.config import Config\n",
    "\n",
    "\n",
    "# Your NewsAPI key\n",
    "api_key = 'de93bf70439d475384fe148401402199'\n",
    "\n",
    "def get_news(query, from_date, to_date, api_key):\n",
    "    url = f'https://newsapi.org/v2/everything?q={query}&from={from_date}&to={to_date}&sortBy=publishedAt&apiKey={api_key}'\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    all_data=[]\n",
    "\n",
    "\n",
    "    if 'articles' in data:\n",
    "        \n",
    "        config = Config(\n",
    "              retries = {\n",
    "             'max_attempts': 10,\n",
    "             'mode': 'standard'\n",
    "             },\n",
    "        connect_timeout=30,\n",
    "        read_timeout=120\n",
    "        ) \n",
    "        acc_key=\"AKIA2DK24S55T5V3RET7\"\n",
    "        sec_key=\"Z9goqsPC1tTyhfo7It6+HXsnG6H//19h77LrLHQf\"\n",
    "        s3 = boto3.client('s3', config=config,aws_access_key_id=acc_key,aws_secret_access_key=sec_key)\n",
    "        pd.DataFrame(data['articles']).to_csv(r'c:\\users\\91904\\news-senti-api.csv')\n",
    "\n",
    "        file = r\"C:\\Users\\91904\\news-senti-api.csv\"\n",
    "        s3.upload_file(file, 'news-senticonomy-bucket', 'news-senti-api.csv')\n",
    "\n",
    "        items=data['articles']\n",
    "        for item in items:\n",
    "          \n",
    "           news_info={'link':item['url'],\n",
    "                      'headline':item['title'],\n",
    "                      'category':query,\n",
    "                     'short_description':item['description'],\n",
    "                    \n",
    "                     'authors':item['author'],\n",
    "                     'date':item['publishedAt']}\n",
    "           all_data.append(news_info) \n",
    "           \n",
    "        return all_data  \n",
    "    else:\n",
    "        print(\"Error fetching news:\", data)\n",
    "        return []\n",
    "\n",
    "def save_news_to_csv(articles, filename):\n",
    "    df2 = pd.DataFrame(articles)\n",
    "    df2['date']=pd.to_datetime(df2['date'], utc=True)\n",
    "    df2['date'] = df2['date'].dt.strftime('%d-%m-%Y')\n",
    "    df2=df2.dropna(how='any',subset=['headline','category','date'])\n",
    "    df2.to_csv(r'c:\\users\\91904\\news-category1.csv')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    print(f'News data saved to {filename}')\n",
    "cat=['SPORTS','EDUCATION','BUSINESS','POLITICS','TECH','SCIENCE','MONEY'] \n",
    "\n",
    "df1=[]\n",
    "\n",
    "for i in cat:\n",
    "    dff=[]\n",
    "    dff=get_news(i,'7.2.2025','7.6.2025','de93bf70439d475384fe148401402199')  \n",
    "    \n",
    "    \n",
    "   \n",
    "    if dff is not None: \n",
    "       \n",
    "        df1.extend(dff) \n",
    "       \n",
    "save_news_to_csv(df1,'news-category1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6a7a3b84-df69-4937-aa7c-466314eadbf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined csv file created successfully\n"
     ]
    }
   ],
   "source": [
    "df3=pd.read_csv(r'c:\\users\\91904\\after-news.csv')\n",
    "df4=pd.read_csv(r'c:\\users\\91904\\news-category1.csv')\n",
    "df3.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "df3['date']=pd.to_datetime(df3['date'])\n",
    "df4.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "df4['date']=pd.to_datetime(df4['date'])\n",
    "combined_df = pd.concat([df3, df4], ignore_index=True)\n",
    "\n",
    "\n",
    "# Save to a new CSV\n",
    "combined_df.to_csv('combined.csv', index=False)\n",
    "print('combined csv file created successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "667c8f8f-7649-406f-ba47-31398ebdaf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r\"C:\\Users\\91904\\combined.csv\"\n",
    "s3.upload_file(file, 'news-senticonomy-bucket', 'combined.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a01428e6-d21f-482f-aee5-c0941ed9ec70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "host=\"news-database.chaswscow6l3.ap-south-1.rds.amazonaws.com\"\n",
    "port=3306\n",
    "username=\"admin\"\n",
    "pa=\"Jeyavani\"\n",
    "db=\"news\"\n",
    "my_conn = create_engine('mysql+pymysql://{0}:{1}@{2}:{3}/{4}'.format(username,pa,host,port,db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f77bf6ff-a5de-405d-a694-5881180c45c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jjjj\n",
      "success\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(r'C:\\Users\\91904\\combined.csv')\n",
    "\n",
    "\n",
    "df.to_sql(\"news_sentiment\",my_conn,if_exists=\"replace\",index=False)\n",
    "print('success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f09580f-bd6e-4103-8a39-9a5ce8ef6c5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
